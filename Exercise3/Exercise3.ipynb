{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8ahoTHxBW82",
        "colab_type": "text"
      },
      "source": [
        "# Exercise 1 (Learning in neural networks)\n",
        "\n",
        "a) Explain the following terms related to neural networks in one to sentences. If you need more sentences this is fine but keep as precise as possible. \n",
        "\n",
        "*   Learning in neural networks\n",
        "*   Training set\n",
        "*   Supervised Learning\n",
        "*   Unsupervised Learning\n",
        "*   Online (incremental) learning\n",
        "*   Offline (batch) learning\n",
        "*   Training error\n",
        "* Generalisation error\n",
        "* Cross-validation\n",
        "\n",
        "\n",
        "b) Name and briefly describe at least two methods to avoid overfitting when training neural networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuKrBzHPHKN5",
        "colab_type": "text"
      },
      "source": [
        "Answer: TODO write your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHDU9m2hChSn",
        "colab_type": "text"
      },
      "source": [
        "# Exercise 2 \n",
        "\n",
        "Missing assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0dZkCh_Cm2n",
        "colab_type": "text"
      },
      "source": [
        "# Exercise 3 (Single-layer perceptron, gradient learning, 2dim. classification)\n",
        "\n",
        "The goal of this exercise is to solve a two-dimensional binary classification problem with gradient learning, using tensorflow.\n",
        "Since the problem is two-dimensional, the perceptron has 2 inputs. Since the classification problem is binary, there is one output.\n",
        "\n",
        "The (two-dimensional) inputs and  corresponding (1-dimensional) for training are provided in *exercise3b_input.txt* and *exercise3b_target.txt* respectivly.\n",
        "To visualize the results, the training samples corresponding to class 1 (output label “0”) have separately been saved in the file *exercise3b_class1.txt*, the training samples corresponding to class 2 (output label “1”) in the file *exercise3b_class2.txt*.\n",
        "\n",
        "The gradient learning algorithm – using the sigmoid activation function – shall be used to provide a solution to this classification problem. Note that due to the sigmoid activation function, the output of the perceptron is a real value in [0,1]:\n",
        "\n",
        "\\begin{equation}\n",
        "sigmoid(h) = \\frac{1}{1+e^{-h}}\n",
        "\\end{equation}\n",
        "To assign a binary class label (either 0 or 1) to an input example, the perceptron output y can\n",
        "be passed through the Heaviside function $\\theta [ y - 0.5 ] $ to yield a binary output $y^{binary}$.\n",
        "Then, any perceptron output between 0.5 and 1 is closer to 1 than to 0 and will be assigned the class label “1”.\n",
        "Conversely, any perceptron output between 0 and $<0.5$ is closer to 0 than to 1 and will be assigned the class label “0”.\n",
        "As usual, denote the weights of the perceptron w1 and w2 and the bias $w0 = -\\theta $.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUX94DzGW0Jh",
        "colab_type": "text"
      },
      "source": [
        "## Task a)\n",
        "\n",
        "Using the above-mentioned post-processing step $\\theta [ y - 0.5 ] $  applied to the perceptron output $y$, show that the decision boundary separating the inputs x=( x1 , x2 ) assigned to class label “1” from those inputs assigned to class label “0” is given by a straight line in two-dimensional space corresponding to the equation (see below at *# plot last decision boundary*)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTKHgBUIW4lY",
        "colab_type": "text"
      },
      "source": [
        "Anwser: TODO enter your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bOBn82oXXU7",
        "colab_type": "text"
      },
      "source": [
        "## Task b)\n",
        "\n",
        "The classification problem (defined by the training data provided in exercise3b_input.txt and the targets provided in exercise3b_target.txt)\n",
        "shall now be solved using the tensorflow keras library.\n",
        "The source code is given below and can be executed by clicking the play button.\n",
        "\n",
        "1.   Train the model for at least three times and report on your findings.\n",
        "2.   Change appropriate parameters (e.g. the learning rate, the batch size, the choice of the solver, potentially the number of epochs etc.) and again report on your findings.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7aTStJHJaay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! git clone https://git.informatik.uni-kiel.de/las/nndl.git\n",
        "\n",
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CXSNwExJb1C",
        "colab_type": "text"
      },
      "source": [
        "Setup for this task. Download data and define Tensorflow version."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6tA_K3-BAyw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from os.path import join\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import Model, Input\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "\n",
        "###-----------------\n",
        "# load training data\n",
        "###-----------------\n",
        "path_to_task = \"nndl/Exercise3\"\n",
        "input = np.loadtxt(join(path_to_task,'exercise3b_input.txt'))\n",
        "tmp = np.loadtxt(join(path_to_task,'exercise3b_target.txt'))\n",
        "target = np.array([tmp[i] for i in range(tmp.size)])\n",
        "class1 = np.loadtxt(join(path_to_task,'exercise3b_class1.txt'))\n",
        "class2 = np.loadtxt(join(path_to_task,'exercise3b_class2.txt'))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iF1QcuBwBFdW",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Define the neural network, here you can change the structure of network, the learning rate and the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HprUKTffLDnq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the structure\n",
        "input_layer = Input(shape=(2,), name='input') # two dimensional input\n",
        "out = Dense(units=1, activation=\"sigmoid\", name=\"output\")(input_layer) # one ouput node with sigmoid activation\n",
        "\n",
        "# create a model\n",
        "model = Model(input_layer, out)\n",
        "\n",
        "# show how the model looks\n",
        "model.summary()\n",
        "\n",
        "# compile the model\n",
        "opt = SGD(learning_rate=0.01)\n",
        "model.compile(optimizer=opt,loss=\"binary_crossentropy\",metrics=[\"acc\"])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idMWZMOMYMv5",
        "colab_type": "text"
      },
      "source": [
        "This line actually trains the model. Changeable parameters batch_size and epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0YZ0ZFcOdI1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train the model\n",
        "history = model.fit(x=input, y=target, batch_size=1, epochs=100, verbose=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNL1qLxHYVbO",
        "colab_type": "text"
      },
      "source": [
        "The following code snippet plots the results you create in the snippet before.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dycq1s9UJ20r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot setup\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 15))\n",
        "legend = []\n",
        "\n",
        "# plot the data\n",
        "axes[0].set_title('Toy classification problem: Data and decision boundaries')\n",
        "axes[0].set_xlabel('x1')\n",
        "axes[0].set_ylabel('x2')\n",
        "minx = min(input[:,0])\n",
        "maxx = max(input[:,0])\n",
        "miny = min(input[:,1])\n",
        "maxy = max(input[:,1])\n",
        "\n",
        "axes[0].set_xlim(minx, maxx)\n",
        "axes[0].set_ylim(miny, maxy) \n",
        "axes[0].plot(class1[:,0], class1[:,1], 'r.', \\\n",
        "    class2[:,0], class2[:,1], 'b.')\n",
        "legend.append('samples class1')\n",
        "legend.append('samples class2')\n",
        "\n",
        "# calculate decision boundary\n",
        "weights = model.layers[-1].get_weights()\n",
        "w0 = weights[1][0] # bias\n",
        "\n",
        "# weights (list of of numpy arrays of shape n_in x n_out)\n",
        "w1 = weights[0][0][0]\n",
        "w2 = weights[0][1][0]\n",
        "if ( w2 == 0 ):\n",
        "    print(\"Error: second weight zero!\")\n",
        "\n",
        "# plot last decision boundary\n",
        "interval = np.arange( np.floor(minx), np.ceil(maxx), 0.1 )\n",
        "line = -w1*interval/w2 - w0/w2\n",
        "args = {'c': 'black', 'linestyle': '-'}\n",
        "axes[0].plot( interval, line, **args)\n",
        "\n",
        "# plot loss curve \n",
        "axes[1].plot(history.history['loss'])\n",
        "axes[1].set_title('Toy classification problem: Loss curve')\n",
        "axes[1].set_xlabel('Epoch number')\n",
        "axes[1].set_ylim(0, 1)\n",
        "axes[1].set_ylabel('loss')\n",
        "\n",
        "# plot loss curve \n",
        "axes[2].plot(history.history['acc'])\n",
        "axes[2].set_title('Toy classification problem: acc curve')\n",
        "axes[2].set_ylim(0, 1)\n",
        "axes[2].set_xlabel('Epoch number')\n",
        "axes[2].set_ylabel('acc')\n",
        "\n",
        "# show the plot\n",
        "fig.legend(axes[0].get_lines(), legend, ncol=3, loc=\"upper center\")\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v19EGJbpYf3k",
        "colab_type": "text"
      },
      "source": [
        "## Answer\n",
        "TODO report your findings here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCk4EokGYqSi",
        "colab_type": "text"
      },
      "source": [
        "**TODO - Further assigments missing**"
      ]
    }
  ]
}