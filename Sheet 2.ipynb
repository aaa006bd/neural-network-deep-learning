{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important Information\n",
    "\n",
    "This file has one usage.\n",
    "1. This file can be displayed in Jupyter. You can read the task and insert your answers here. Start the notebook from an Anaconda prompt and change to the working directory containing the *.ipynb file.\n",
    "\n",
    "**For submission**, upload a pdf based on this jupyter notebook. The recommended way is opening the Print Preview (File -> Print Preview) and using a PDF printer. Avoid to generate too large cells: If a cell contains more content than which fits on a normal DIN A4 page, the content will be cut during  printing. A solution to this is to split up the cell into several smaller cells.\n",
    "\n",
    "Mathematical formulations can be inserted with the MathJax (a subset of Latex commands) or as images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1  (Single-layer perceptron and Boolean functions with 2 inputs)\n",
    "\n",
    "a) Show that the Boolean function XOR cannot be realized by a (single-layer) perceptron (with 2 inputs).\n",
    "\n",
    "*Note: The output y of a single-layer perceptron with 2 inputs  $x_1$ and $x_2$, threshold $\\theta$ and weights $w_1$ and $w_2$ is given by $y = \\Theta [x_1 w_1 + x_2 w_2 - \\theta]$*<br>\n",
    "*($\\Theta$ is the Heaviside function)*\n",
    "\n",
    "![IMAGE: perceptron](images/perceptron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "Write your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Give all Boolean functions with 2 inputs (i.e. for each Boolean function: the output for each input combination) and indicate whether they can be realized by a (single-layer) perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "Write your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Select three Boolean functions with two inputs and give values for the synaptic weights\n",
    "$w_1$,$w_2$ and threshold $\\theta$ so that the Boolean function is realized by a single-layer\n",
    "perceptron. Show for each of the three Boolean functions and each input pair that the\n",
    "Boolean function is indeed realized by the chosen combination of weights and threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "Write your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d)\tWhich of the following partitioning of $\\Re^2$ can be realized by a single-layer perceptron with two inputs? For those that can be realized, give weights and threshold of the perceptron. (Consider abscissa as $x_1$  and ordinate as $x_2$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " i) | ii) | iii)\n",
    "- | - | -\n",
    "![image](images/1d-i.png) |![image](images/1d-ii.png) |![image](images/1d-iii.png)\n",
    "\n",
    " iv) | v) | vi)\n",
    "- | - | -\n",
    "![image](images/1d-iv.png) |![image](images/1d-v.png) |![image](images/1d-vi.png)\n",
    "\n",
    "\n",
    "(From: Riedmiller)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "Write your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 (Types of neural networks, synaptic weight matrix)\n",
    "\n",
    "a)\tExplain the following terms related to neural networks:\n",
    "\n",
    "* Boolean function\n",
    "* Feedforward neural network\n",
    "* Recurrent neural network\n",
    "* Multi-layer perceptron\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "Write your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b)\tSpecify whether the following artificial neural networks are feedforward or recurrent neural networks and explain your selection.\n",
    "\n",
    "\n",
    " i) | ii) \n",
    "- | -\n",
    "![image](images/network-a.png) |![image](images/network-b.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "Write your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c)\tUsing the neuron numbers from 1 to 7 given in the circles, fill out the following general weight matrix by marking the corresponding field entries. Example: Mark the field in row $i$ and column $j$ (weight $w_{ij}$) if there is a connection from neuron $j$ to neuron $i$.\n",
    "\n",
    "![image](images/matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "Write your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3 (Computing the output of a feedforward neural network)\n",
    "\n",
    "a) Compute the output of the following feedforward neural network for the input  $x_1 = 3$; $x_2 = 1$. <br>\n",
    "    Which neurons can be computed in parallel, which have to wait?\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network:\n",
    "\n",
    "![network](images/exercise3.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: \n",
    "* The small numbers in each circle correspond to the components of the weight vector; see example below.  In this part of the exercise, the threshold is set to $\\theta$ =0 for all neurons.\n",
    "* c is the slope of the linear activation function:  $f(h) = c \\cdot h$\n",
    "* “Threshold element” means that the activation function is the Heaviside function\n",
    "![image](images/exercise3-explanation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example for weight vector of neuron 8: <br>\n",
    "1st component of weight vector (1) refers to connection neuron 3 $\\rightarrow$ neuron 8 <br>\n",
    "2nd component of weight vector (-2) refers to connection neuron 4 $\\rightarrow$ neuron 8 <br>\n",
    "3rd component of weight vector (3) refers to connection neuron 5 $\\rightarrow$ neuron 8 <br>\n",
    "4th component of weight vector (8) refers to connection neuron 6 $\\rightarrow$ neuron 8 <br>\n",
    "\n",
    "(Source: Stefan Hartmann, Cesar Research)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "#### State of neurons: s[ ]\n",
    "#### First layer: \n",
    "x[1] = 3 , x[2] =1, w[1][0] = 1, w[2][0] = 1.<br>\n",
    "linear activation function with slope c = 1.<br>\n",
    "s[1] = ( 3 * 1) = 3<br>\n",
    "s[2] = ( 1 * 1) = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2nd layer:\n",
    "\n",
    "w[3][1] = 1, w[3][2] = -2, <br>\n",
    "w[4][1] = -1, w[4][2] = 0, <br>\n",
    "w[5][1] = 3, w[5][2] = 2,<br>\n",
    "w[6][1] = 0, w[6][2] = 2 and <br>\n",
    "threshold element  $\\theta$ = 0.<br><br>\n",
    "s[3] = $\\Theta$(3 * 1 + 1 * (-2) - $\\theta$) = $\\Theta$(1) = 1 <br>\n",
    "s[4] = $\\Theta$(3 * (-1) + 1 * 0 - $\\theta$) = $\\Theta$(-3) = 0 <br>\n",
    "s[5] = $\\Theta$(3 * (3) + 1 * 2 - $\\theta$) = $\\Theta$(11) = 1 <br>\n",
    "s[6] = $\\Theta$(3 * 0 + 1 * 2 - $\\theta$) = $\\Theta$(2) = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3rd layer\n",
    "w[7][3] = 0, w[7][4] = 2, w[7][5] = -3, w[7][6] = 1 <br>\n",
    "w[8][3] = 1, w[8][4] = -2, w[8][5] = 3, w[8][6] = 8 <br>\n",
    "w[9][3] = 0, w[9][4] = 2, w[9][5] = 3, w[9][6] = -4 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linear activation function with slope c = 1.<br> <br>\n",
    "s[7] = (1 * 0 + 0 * 2 + 1 * (-3) + 1 * 1 - 0) = -2<br>\n",
    "s[8] = (1 * 1 + 0 * (-2) + 1 * 3 + 1 * 8 - 0) = 12<br>\n",
    "s[9] = (1 * 0 + 0 * 2 + 1 * 3 + 1 * (-4) - 0) = -1<br>\n",
    "\n",
    "#### output\n",
    "y[1] = -2 <br>\n",
    "y[2] = 12 <br>\n",
    "y[3] = -1 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### output\n",
    "y[1] = -2 <br>\n",
    "y[2] = 12 <br>\n",
    "y[3] = -1 <br> <br>\n",
    "i.   Neuron 1 and 2 can be computed in parallel. <br>\n",
    "ii.  Neuron 3, 4, 5 and 6 can be computed in parallel. <br>\n",
    "iii. Neuron 7, 8 and 9 can be computed in parallel. <br>\n",
    "Computation of neurons in a layer dependent on the computation of the previous layer. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Assume the following weight matrix, where an entry $w_{ij}$ (ith row, jth column) corresponds to the synaptic weight from neuron $j$ to neuron $i$. (No entry means the synaptic weight is 0).\n",
    "\n",
    "Further assume that the activation function of the neurons of hidden layer 2 (neurons 8, 9 and 10) is linear (with slope $c=1$), whereas the activation function of all other neurons is a Heaviside step function.\n",
    "\n",
    "In this part of the exercise, the threshold $\\theta$ of each node is indicated in the network graph as number in the corresponding neuron.\n",
    "\n",
    "Compute the output of the following feedforward neural network for the inputs $x_1 = 1$, $x_2 = 0$, $x_3 = 1$ and  $x_1 = 0$, $x_2 = 1$, $x_3 = 1$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight matrix:\n",
    "![weight-matrix](images/weight-matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network:\n",
    "![network](images/network3.png)    \n",
    "*Note: this is a feedforward neural network of second order*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "#### First layer:\n",
    "w[4][1] = -2 , w[4][2] = 5, w[4][3] = -4<br>\n",
    "w[5][1] = 1 , w[5][2] = -2 <br>\n",
    "w[6][1] = 3, w[6][2] = -1, w[6][3] = 6 <br>\n",
    "w[7][2] = 7, w[7][3] = 1 <br>\n",
    "\n",
    "$\\theta$ [4] = 1.5, $\\theta$[5] = 0.5, $\\theta$[6] = -0.5, $\\theta$[7] = 0.5 <br><br>\n",
    "x4 = $\\Theta$ (1 * (-2) + 0 * 5 + 1 * (-4) - 1.5) = Θ(-7.5) = 0 <br>\n",
    "x5=  $\\Theta$ (1 * 1 + 0 * (-2) - 0.5) =  $\\Theta$(0.5) = 1 <br>\n",
    "x6 = $\\Theta$ (1 * 3 + 0 * (-1) + 1 * 6 + 0.5) =  $\\Theta$(9.5) = 1 <br>\n",
    "x7 = $\\Theta$ ( 0 * 7 + 1 * 1 – 0.5) =  $\\Theta$(0.5) = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second layer\n",
    "w[8][4] = -1 , w[8][5] = 4, w[8][6] = -2 <br>\n",
    "w[9][5] = -3 , w[9][6] = 5, w[9][7] = 1 <br>\n",
    "w[10][4] = 8, w[6][5] = 2, w[6][7] = -3 <br><br>\n",
    "$\\theta$  [8] = -0.5, $\\theta$ [9] = 1.5, $\\theta$ [10] = -1 <br><br>\n",
    "Linear activation function with slope c = 1. <br><br>\n",
    "x[8] = 0 * (-1) + 1 * 4 + 1 * (-2) + 0.5 = 2.5 <br>\n",
    "x[9] = 1 * (-3) + 1 * 5 + 1 * 1 – 1.5= 1.5 <br>\n",
    "x[10] = 0 * 8 + 1 * 2 + 1 * (-3) + 1= 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3rd layer:\n",
    "w[11][7] = 6, w[11][8] = 1, w[11][9] = -2<br>\n",
    "w[12][6] = 1, w[11][9] = -4, w[11][10] = 3<br><br>\n",
    "$\\theta$[11] = -1.5, $\\theta$[12] = 1.5 <br><br>\n",
    "X[11] =$\\Theta$(1 * 6 + 2.5 * 1 + 1.5 * (-2) + 1.5) = $\\Theta$(7) = 1 <br>\n",
    "X[12] = $\\Theta$(1 * 1 + 1.5 * (-4) + 0 * 3 - 1.5) = $\\Theta$(-6.5) = 0<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### output \n",
    "x[11] = 1 and x[12] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4 (Multi-layer perceptron and XOR):\n",
    "a) Find a multi-layer perceptron which realizes the Boolean function XOR. Demonstrate that\n",
    "the found perceptron indeed performs XOR on all possible input pairs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "![xor-network](images/XOR.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assinging weights\n",
    "\n",
    "w[3][1] = 20,  w[3][2] = 20 <br>\n",
    "w[4][1] = -20,  w[4][2] = -20 <br>\n",
    "w[5][3] = 20,  w[5][4] = 20 <br>\n",
    "$\\theta$ [3] = 10, $\\theta$[4] = 30,  $\\theta$ [5] = -30 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  when x1 = 0, x2 =  0\n",
    "\n",
    "#### second layer \n",
    "x[3] = $\\Theta$ (0 $\\ast$ 20 + 0 * 20 - 10) = $\\Theta$(-10) = 0 <br>\n",
    "x[4] = $\\Theta$ (0 * -20 + 0 * -20 + 30) = $\\Theta$(30) = 1 <br>\n",
    "\n",
    "#### Third layer\n",
    "x[5] = $\\Theta$(0 * 20 + 1 * 20 - 30) = $\\Theta$(-10) = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  when x1 = 0, x2 =  1\n",
    "\n",
    "#### second layer \n",
    "x[3] = $\\Theta$ (0 $\\ast$ 20 + 1 * 20 - 10) = $\\Theta$(10) = 1 <br>\n",
    "x[4] = $\\Theta$ (0 * -20 + 1 * -20 + 30) = $\\Theta$(10) = 1 <br>\n",
    "\n",
    "#### Third layer\n",
    "x[5] = $\\Theta$(1 * 20 + 1 * 20 - 30) = $\\Theta$(10) = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  when x1 = 1, x2 =  0\n",
    "\n",
    "#### second layer \n",
    "x[3] = $\\Theta$ (1 $\\ast$ 20 + 0 * 20 - 10) = $\\Theta$(10) = 1 <br>\n",
    "x[4] = $\\Theta$ (1 * -20 + 0 * -20 + 30) = $\\Theta$(10) = 1 <br>\n",
    "\n",
    "#### Third layer\n",
    "x[5] = $\\Theta$(1 * 20 + 1 * 20 - 30) = $\\Theta$(10) = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  when x1 = 1, x2 =  1\n",
    "\n",
    "#### second layer \n",
    "x[3] = $\\Theta$ (1 $\\ast$ 20 + 1 * 20 - 10) = $\\Theta$(30) = 1 <br>\n",
    "x[4] = $\\Theta$ (1 * -20 + 1 * -20 + 30) = $\\Theta$(-10) = 0 <br>\n",
    "\n",
    "#### Third layer\n",
    "x[5] = $\\Theta$(1 * 20 + 0 * 20 - 30) = $\\Theta$(-10) = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Find a perceptron with two (binary) inputs which realizes the function\n",
    "\n",
    "$F(x_1,x_2) = \n",
    "\\begin{cases}\n",
    "1  & \\text{if $x_1 + x_2 = 1$} \\\\\n",
    "0 & \\text{else}\n",
    "\\end{cases} \n",
    "$\n",
    "\n",
    "*Note: “+” denotes mathematical addition.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "This funciton is working exactly as XOR function which is already described above "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
